[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Analysis of Power and Thermal Behavior in HPC Supercomputers",
    "section": "",
    "text": "1 Introduction\nThis topic combines my domain knowledge expertise in power and thermal phenomena with an area I have interest in further exploring, HPC supercomputers. HPC supercomputers are used for solving highly complex problems that require immense computational power by combining high speed networking and thousands of processors. There are some power and thermal issues that can arise which can lead to performance degradation, increased power consumption, and reduced hardware longevity.\nI aim to study and further explore trends with the following questions: What is the relationship between power draw and temperature across CPUs and GPUs? Can we visually identify anomalies such as sudden temperature spikes, power surges, or cooling failures? How do thermal and power distributions vary across nodes, and can differences reveal nonuniform aging or cooling performance?",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "2  Data",
    "section": "",
    "text": "2.1 Description\nThe data used for this project is from Oak Ridge National Laboratory: https://doi.ccs.ornl.gov/dataset/086578e9-8a9f-56b1-a657-0ed8b7393deb. I will be using a_fullperiod_10sec_58hosts.tar which is one of the sample subsets in that dataset package. It contains 10-second mean telemetry (power + temperature) across 58 nodes, spanning multiple months between 2020–2022.\nThe data is collected by the lab’s systems administrators and monitoring infrastructure. It is sampled at 1 Hz for multiple nodes across the supercomputer. The format is in parquet files where each contains time series measurements for multiple nodes. The data fields include information such as time stamps, hostname/node ID, CPU and GPU power and temperature readings, and some additional sensor readings. The data collection was completed in 2022 for this set, therefore it is no longer actively being updated.\nFor this project’s purposes I selected 3 nodes and a continuous 7 day period from the most recent data collection year of 2022. This subset provides enough cross node variation to explore power and temperature relationships, identify anomalies, and compare operational behavior. HPC telemetry produces millions of rows of data so restricting to a smaller sample ensures all visuals remain interpretable and reproducible. Additionally, large supercomputers such as this one use homogeneous hardware so the nodes in the same rack or partition tend to show similar behavior.\nCode\nlibrary(arrow)\nlibrary(lubridate)\nlibrary(naniar)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#data-loading",
    "href": "data.html#data-loading",
    "title": "2  Data",
    "section": "2.2 Data Loading",
    "text": "2.2 Data Loading\n\n\nCode\nnode_files &lt;- list(\n  a07n04 = c(\n    \"~/Desktop/EDAV/Final Project/a_fullperiod_10sec_58hosts_decomp/a07n04/202201/20220101.parquet\",\n    \"~/Desktop/EDAV/Final Project/a_fullperiod_10sec_58hosts_decomp/a07n04/202201/20220102.parquet\",\n    \"~/Desktop/EDAV/Final Project/a_fullperiod_10sec_58hosts_decomp/a07n04/202201/20220103.parquet\",\n    \"~/Desktop/EDAV/Final Project/a_fullperiod_10sec_58hosts_decomp/a07n04/202201/20220104.parquet\",\n    \"~/Desktop/EDAV/Final Project/a_fullperiod_10sec_58hosts_decomp/a07n04/202201/20220105.parquet\",\n    \"~/Desktop/EDAV/Final Project/a_fullperiod_10sec_58hosts_decomp/a07n04/202201/20220106.parquet\",\n    \"~/Desktop/EDAV/Final Project/a_fullperiod_10sec_58hosts_decomp/a07n04/202201/20220107.parquet\"\n  ),\n  \n  b03n06 = c(\n    \"~/Desktop/EDAV/Final Project/a_fullperiod_10sec_58hosts_decomp/b03n06/202201/20220101.parquet\",\n    \"~/Desktop/EDAV/Final Project/a_fullperiod_10sec_58hosts_decomp/b03n06/202201/20220102.parquet\",\n    \"~/Desktop/EDAV/Final Project/a_fullperiod_10sec_58hosts_decomp/b03n06/202201/20220103.parquet\",\n    \"~/Desktop/EDAV/Final Project/a_fullperiod_10sec_58hosts_decomp/b03n06/202201/20220104.parquet\",\n    \"~/Desktop/EDAV/Final Project/a_fullperiod_10sec_58hosts_decomp/b03n06/202201/20220105.parquet\",\n    \"~/Desktop/EDAV/Final Project/a_fullperiod_10sec_58hosts_decomp/b03n06/202201/20220106.parquet\",\n    \"~/Desktop/EDAV/Final Project/a_fullperiod_10sec_58hosts_decomp/b03n06/202201/20220107.parquet\"\n  ),\n  \n  c03n13 = c(\n    \"~/Desktop/EDAV/Final Project/a_fullperiod_10sec_58hosts_decomp/c03n13/202201/20220101.parquet\",\n    \"~/Desktop/EDAV/Final Project/a_fullperiod_10sec_58hosts_decomp/c03n13/202201/20220102.parquet\",\n    \"~/Desktop/EDAV/Final Project/a_fullperiod_10sec_58hosts_decomp/c03n13/202201/20220103.parquet\",\n    \"~/Desktop/EDAV/Final Project/a_fullperiod_10sec_58hosts_decomp/c03n13/202201/20220104.parquet\",\n    \"~/Desktop/EDAV/Final Project/a_fullperiod_10sec_58hosts_decomp/c03n13/202201/20220105.parquet\",\n    \"~/Desktop/EDAV/Final Project/a_fullperiod_10sec_58hosts_decomp/c03n13/202201/20220106.parquet\",\n    \"~/Desktop/EDAV/Final Project/a_fullperiod_10sec_58hosts_decomp/c03n13/202201/20220107.parquet\"\n  )\n)\n\ndf_all &lt;- do.call(\n  rbind,\n  lapply(names(node_files), function(node_name) {\n    do.call(\n      rbind,\n      lapply(node_files[[node_name]], function(path) {\n        df &lt;- read_parquet(path)\n        df$node &lt;- node_name\n        df\n      })\n    )\n  })\n)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#missing-value-analysis",
    "href": "data.html#missing-value-analysis",
    "title": "2  Data",
    "section": "2.3 Missing value analysis",
    "text": "2.3 Missing value analysis\nMissing values could occur due to sensor glitches, communication drops, or system resets. The plots below include a missing value heatmap and a bar plot showing aggregated missing patterns if any are present.\n\n\nCode\n# Missing Value Heatmap\ndf_all |&gt;\n  select(all_of(names(df_all))) |&gt;\n  vis_miss(warn_large_data = FALSE) +\n  labs(\n    title = \"Missing Value Heatmap\",\n    x = NULL,\n    y = \"Observation Index\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(axis.text.x = element_text(angle = 90, hjust = 0, size = 7))\n\n\n\n\n\n\n\n\n\nCode\n# Aggregated Missing Patterns Bar Chart\ndf_missing_pct &lt;- df_all |&gt; \n  summarise(across(everything(), ~ mean(is.na(.)) * 100)) |&gt; \n  pivot_longer(\n    cols = everything(),\n    names_to = \"variable\",\n    values_to = \"pct_missing\"\n  )\n\n# Plot with y-axis zoom so 0% bars are visible\nggplot(df_missing_pct, \n       aes(x = pct_missing, y = reorder(variable, pct_missing))) +\n  geom_col(fill = \"gray70\", color = \"black\", width = 0.7) +\n  scale_x_continuous(\n    limits = c(0, 0.5), \n    breaks = c(0, 0.1, 0.2, 0.3, 0.4, 0.5),\n    labels = scales::percent_format(accuracy = 1)\n  ) +\n  labs(\n    title = \"Percentage of Missing Values\",\n    x = \"Percent Missing\",\n    y = \"Variable\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    axis.text.y = element_text(size = 6, hjust = 1),   \n    plot.title = element_text(face = \"bold\", size = 18)\n  )\n\n\n\n\n\n\n\n\n\nBoth the heatmap and bar chart confirm that there are no missing values present in this data set. This is very typical of machine generated telemetry since the sensors report at fixed intervals. For the bar chart, adding a truncated y-axis allows visual confirmation that all missing percentages are 0%, and the heatmap is filled with a singular color indicating no missing values as well.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "data.html#data-cleaning",
    "href": "data.html#data-cleaning",
    "title": "2  Data",
    "section": "2.4 Data Cleaning",
    "text": "2.4 Data Cleaning\n\n\nCode\n# Clean Variables\ndf_all &lt;- df_all |&gt;\n  mutate(\n    date  = as.Date(timestamp),\n    hour  = lubridate::hour(timestamp),\n    cpu_temp = (p0_core_temp_mean + p1_core_temp_mean) / 2,\n    gpu_temp = rowMeans(across(gpu0_core_temp:gpu5_core_temp), na.rm = TRUE),\n    gpu_power_total =\n      p0_gpu0_power + p0_gpu1_power + p0_gpu2_power +\n      p1_gpu0_power + p1_gpu1_power + p1_gpu2_power\n  )\n\ndf_daily &lt;- df_all |&gt;\n  mutate(date = as.Date(timestamp)) |&gt;\n  group_by(node, date) |&gt;\n  summarise(\n    cpu_temp = mean(cpu_temp, na.rm = TRUE),\n    gpu_temp = mean(gpu_temp, na.rm = TRUE),\n    cpu_power = mean(p0_power + p1_power, na.rm = TRUE),\n    gpu_power = mean(gpu_power_total, na.rm = TRUE),\n    .groups = \"drop\"\n  )\n\n# Save Cleaned to Read into results.qmd\nsaveRDS(df_all, \"data/clean/hpc_3nodes_7days.rds\")\nsaveRDS(df_daily, \"data/clean/hpc_daily_3nodes_7days.rds\")",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Data</span>"
    ]
  },
  {
    "objectID": "results.html",
    "href": "results.html",
    "title": "3  Results",
    "section": "",
    "text": "3.1 Short Summary\nAcross the three computing nodes studied, temperature and power were closely related. Whenever the processing units worked harder, they drew more power and heated up almost immediately. While most of the week showed routine low temperature operation, each node also had short bursts of heat and power, which made unusual activity easy to spot. When coming their overall behavior, the nodes shared similar baseline performance, however, their power and temperature distributions uncovered some nodes may handle more demanding jobs or experience different cooling conditions. These patterns reveal how power usage, temperature, and occasional anomalies can vary within the same machine, offering insight into each node’s operational health.\nCode\nlibrary(arrow)\nlibrary(dplyr)\nlibrary(zoo)\nlibrary(dplyr)\nlibrary(GGally)\nlibrary(lubridate)\nlibrary(ggplot2)\nlibrary(vcd)\nlibrary(RColorBrewer)\nlibrary(hexbin)\ndf_all &lt;- readRDS(\"data/clean/hpc_3nodes_7days.rds\")\ndf_daily &lt;- readRDS(\"data/clean/hpc_daily_3nodes_7days.rds\")",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "results.html#power-thermal-relationship",
    "href": "results.html#power-thermal-relationship",
    "title": "3  Results",
    "section": "3.2 Power-Thermal Relationship",
    "text": "3.2 Power-Thermal Relationship\n\n\nCode\nggplot(df_all, aes(timestamp, cpu_temp)) +\n  geom_line(alpha = 0.4) +\n  facet_wrap(~ node, ncol = 1) +\n  labs(\n    title = \"CPU Temperature Over Time Across Three HPC Nodes\",\n    x = \"Time\",\n    y = \"CPU Temperature (°C)\"\n  ) +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n\n\nNodes a07n04 and b03n06 show nearly identical thermal behavior, with quick temperature spikes around January 1st and again near January 7th. Node c03n13 exhibits the strongest and most sustained heat events, indicating heavier or more prolonged computational activity on that node. These spikes are consistent with increased processor workload because when CPUs draw more power to handle demanding tasks, the resulting electrical load converts almost immediately into additional heat, producing the thermal spikes visible in the plot.\n\n\nCode\nggplot(df_all, aes(timestamp, gpu_power_total)) +\n  geom_line(alpha = 0.4) +\n  facet_wrap(~ node, ncol = 1) +\n  labs(\n    title = \"GPU Total Power Over Time Across Three HPC Nodes\",\n    x = \"Time\",\n    y = \"GPU Power (W)\"\n  ) +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n\n\nThe bursts of power correspond to GPU heavy jobs being scheduled which can be seen across a lot of the days which many indicate coordinated workloads rather than random usage. Node a07n04 has the longest sustained GPU load around January 4th and 7th. Nodes b03n06 and c03n13 seem to have frequent burst patterns too but with shorter durations, which may mean they handled briefer GPU tasks this week.\n\n\nCode\ndf_roll &lt;- df_all |&gt;\n  filter(node == \"a07n04\") |&gt;\n  arrange(timestamp) |&gt;\n  mutate(cpu_roll = rollmean(cpu_temp, k = 300, fill = NA))\n\nggplot(df_roll, aes(timestamp)) +\n  geom_line(aes(y = cpu_temp), alpha = 0.3) +\n  geom_line(aes(y = cpu_roll), color = \"red\") +\n  labs(\n    title = \"CPU Temperature with 50-Minute Rolling Average\",\n    x = \"Time\",\n    y = \"Temperature (°C)\"\n  ) +\n  theme_minimal(base_size = 16)\n\n\n\n\n\n\n\n\n\nShort, sharp spikes from the raw line become clearer where node a07n04 experiences two major period of sustained heating corresponding to heightened computational load. Outside these periods, the smoothed line seems to tightly stay between 28-30 degrees C meaning the system returns quickly to its baseline temperature once the workload subsides. This plot smooths our noise and shows the underlying thermal pattern of the node behind the high frequency fluctuations.\n\n\nCode\ndf_heat &lt;- df_all |&gt;\n  mutate(\n    hour = hour(timestamp),\n    date = as.Date(timestamp)\n  )\n\nggplot(df_heat, aes(hour, date, fill = cpu_temp)) +\n  geom_tile() +\n  scale_fill_viridis_c() +\n  facet_wrap(~ node, ncol = 1) +\n  labs(\n    title = \"Daily CPU Temperature Patterns by Hour\",\n    x = \"Hour of Day\",\n    y = \"Date\"\n  ) +\n  theme_minimal(base_size = 16)\n\n\n\n\n\n\n\n\n\nThe heatmap shows that all nodes stay near their baseline temperatures for most hours. Nodes a07n04 and b03n06 have isolated hot spots whereas c03n13 shows a full extended hot spot early on January 1st, which is consistent with its stronger workload bursts seen in earlier plots.\n\n\nCode\nggplot(df_all, aes(gpu_temp, gpu_power_total)) +\n  geom_hex() +\n  scale_fill_gradient(low = \"grey\", high = \"purple\") +\n  labs(\n    title = \"GPU Temperature vs GPU Power\",\n    x = \"GPU Temperature (°C)\",\n    y = \"GPU Power (W)\",\n    fill = \"Count\"\n  ) +\n  theme_minimal(base_size = 16)\n\n\n\n\n\n\n\n\n\nThe hexbin plot shows as GPU temperature increases, GPU power consumption also increases which indicates strong power-thermal coupling across all nodes. Most activity clusters are at lower temperatures while the higher power and higher temperature bins become sparser which shows extreme loads are rare but thermally intense.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "results.html#operational-anomalies",
    "href": "results.html#operational-anomalies",
    "title": "3  Results",
    "section": "3.3 Operational Anomalies",
    "text": "3.3 Operational Anomalies\n\n\nCode\ncpu_thresh &lt;- quantile(df_all$cpu_temp, 0.95, na.rm = TRUE)\n\ndf_plot &lt;- df_all |&gt;\n  mutate(anom = cpu_temp &gt; cpu_thresh)\n\nggplot(df_plot, aes(timestamp, cpu_temp)) +\n  geom_line(alpha = 0.3) +\ngeom_point(\n  data = df_plot |&gt; filter(anom),\n  aes(timestamp, cpu_temp),\n  color = \"red\",\n  shape = \".\"\n) +\n  facet_wrap(~ node, ncol = 1) +\n  labs(\n    title = \"CPU Temperature Anomalies\",\n    x = \"Time\",\n    y = \"Temperature (°C)\"\n  ) +\n  theme_minimal(base_size = 16)\n\n\n\n\n\n\n\n\n\nUsing the top 5% of CPU temperatures as an anomaly threshold, nodes a07n04 and b03n06 show only brief and isolated spikes, whereas c03n13 shows long runs of consecutive high temperatures. This clustering of high temperature outliers shows thermal stress which may indicate less effective cooling or early signs of node-specific thermal anomalies such as degradation.\n\n\nCode\ngpu_thresh &lt;- quantile(df_all$gpu_power_total, 0.95, na.rm = TRUE)\n\ndf_power_anom &lt;- df_all |&gt;\n  mutate(power_anom = gpu_power_total &gt; gpu_thresh)\n\nggplot(df_power_anom, aes(timestamp, gpu_power_total)) +\n  geom_line(alpha = 0.3) +\n  geom_point(\n    data = df_power_anom |&gt; filter(power_anom),\n    aes(timestamp, gpu_power_total),\n    color = \"red\",\n    shape = \".\" \n  ) +\n  facet_wrap(~ node, ncol = 1) +\n  labs(\n    title = \"GPU Power Anomalies\",\n    x = \"Time\",\n    y = \"GPU Power (W)\"\n  ) +\n  theme_minimal(base_size = 16)\n\n\n\n\n\n\n\n\n\nThe red points are the top 5% of GPU power readings representing rare periods where power draw exceeds the node’s typically operating range. These spikes may indicate anomalies such as unexpected GPU heavy jobs, scheduler misallocation, or power capping failures. Node a07n04 shows the most frequent high power events potentially suggesting hardware or cooling irregularities.\n\n\nCode\ndf_trc &lt;- df_all |&gt;\n  mutate(\n    date = as.Date(timestamp)\n  )\n\nggplot(df_trc, aes(gpu_power_total, gpu_temp, color = factor(date))) +\n  geom_smooth(method = \"lm\", se = FALSE, linewidth = 1.1) +\n  facet_wrap(~ node, scales = \"free\") +\n  scale_color_viridis_d(name = \"Date\") +\n  labs(\n    title = \"Thermal Response Curve: GPU Temperature vs GPU Power\",\n    x = \"GPU Power (W)\",\n    y = \"GPU Temperature (°C)\"\n  ) +\n  theme_minimal(base_size = 16)\n\n\n\n\n\n\n\n\n\nThe GPU temperature–power relationship for node a07n04 becomes increasingly steep from January 4 to January 7. A growing slope indicates reduced thermal efficiency where the node is producing more heat per watt of GPU power. This pattern is consistent with temporary cooling stress or early signs of thermal degradation. While this does not prove hardware aging directly, it does suggest that the system operated under less favorable cooling conditions.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "results.html#cross-node-comparison",
    "href": "results.html#cross-node-comparison",
    "title": "3  Results",
    "section": "3.4 Cross Node Comparison",
    "text": "3.4 Cross Node Comparison\n\n\nCode\nGGally::ggparcoord(\n  df_daily,\n  columns = which(names(df_daily) %in% c(\"cpu_temp\", \"gpu_temp\", \"gpu_power\", \"cpu_power\")),\n  groupColumn = \"node\",\n  scale = \"center\"\n) +\n  labs(title = \"Daily Metrics per Node\",\n       x = \"Metric\", y = \"Scaled Value\") +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n\n\nNodes a07n04 and b03n06 show many crossing lines, meaning their power and temperature metrics vary independently from day to day. Node c03n13 shows more aligned patterns, indicating its thermal and power metrics rise and fall together. This tighter coupling suggests heavier sustained use and a higher likelihood of non-uniform aging.\n\n\nCode\n# Compute medians to define ordering\nnode_order &lt;- df_all |&gt;\n  group_by(node) |&gt;\n  summarise(med = median(cpu_temp, na.rm = TRUE)) |&gt;\n  arrange(desc(med)) |&gt;\n  pull(node)\n\nggplot(df_all, aes(factor(node, levels = node_order), cpu_temp)) +\n  geom_boxplot(fill = \"lightgray\",\n               outlier.size = 0.6) +\n  labs(\n    title = \"CPU Temperature Distribution by Nodes\",\n    x = \"Node\",\n    y = \"Temperature (°C)\"\n  ) +\n  theme_minimal(base_size = 16)\n\n\n\n\n\n\n\n\n\nNode c03n13 has the highest median CPU temperature, wide spread of temperatures, and the most extreme outliers meaning it consistently runs hotter than the other nodes. Nodes a07n04 and b03n06 are more tightly clustered indicating more stable thermal behavior.\n\n\nCode\nggplot(df_all, aes(gpu_temp, color = node, fill = node)) +\n  geom_density(alpha = 0.15, bw = 0.8, linewidth = 1.1) +\n  scale_color_manual(values = c(\"a07n04\" = \"#7FB3D5\",\n                                \"b03n06\" = \"#F5B7B1\",\n                                \"c03n13\" = \"#C39BD3\")) +\n  scale_fill_manual(values = c(\"a07n04\" = \"#7FB3D5\",\n                               \"b03n06\" = \"#F5B7B1\",\n                               \"c03n13\" = \"#C39BD3\")) +\n  labs(\n    title = \"GPU Temperature Distributions Across Nodes\",\n    x = \"GPU Temperature (°C)\",\n    y = \"Density\"\n  ) +\n  theme_minimal(base_size = 16)\n\n\n\n\n\n\n\n\n\nNode b03n06 has the lowest GPU temperature operating range and node a07n04 has the strongest right-tail indicating more frequent higher GPU temperatures compared to other nodes. Node c03n13 also has elevated temperatures but its upper tail is shorter meaning the higher temperatures were more concentrated in shorter bursts. Overall, nodes operate similarly at baseline, but a07n04 is the warmest under load, aligning with patterns seen in the anomaly and thermal-response plots.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Results</span>"
    ]
  },
  {
    "objectID": "conclusion.html",
    "href": "conclusion.html",
    "title": "4  Conclusion",
    "section": "",
    "text": "Across the three sampled nodes, power and temperature behaved in directly correlated patterns that reflected their computational loads. The analysis examined only a small subset of the full supercomputer system, so longer time spans and more nodes would be needed to confirm system wide patterns. Future work could incorporate airflow patterns, predictive models to improve early detection of non uniform aging or degradation, and metadata to identify causes behind thermal and power anomalies. Overall, the project still demonstrated how exploratory visualization can reveal important operational behaviors in large scale computing systems.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Conclusion</span>"
    ]
  }
]